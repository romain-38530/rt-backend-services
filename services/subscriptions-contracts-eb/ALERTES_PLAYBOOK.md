# Playbook des Alertes - RT SYMPHONI.A

## Version: 1.0.0
## Module: subscriptions-contracts-eb

---

## Table des mati√®res

1. [Introduction](#introduction)
2. [Alertes Infrastructure](#alertes-infrastructure)
3. [Alertes Application](#alertes-application)
4. [Alertes Business](#alertes-business)
5. [Proc√©dures d'escalade](#proc√©dures-descalade)
6. [Contacts d'urgence](#contacts-durgence)

---

## Introduction

Ce document d√©crit les actions √† entreprendre pour chaque alerte CloudWatch. Chaque section contient:

- **Description**: Ce que signifie l'alerte
- **Impact**: Cons√©quences potentielles
- **Diagnostic**: Comment investiguer
- **Actions**: Que faire pour r√©soudre
- **Pr√©vention**: Comment √©viter √† l'avenir

---

## Alertes Infrastructure

### üî¥ CRITICAL: High CPU Utilization (>95%)

**Description**: L'utilisation CPU d√©passe 95%

**Impact**:
- Ralentissement g√©n√©ral de l'application
- Timeout des requ√™tes API
- Risque de crash du processus Node.js

**Diagnostic**:

1. V√©rifier les m√©triques CPU:
   ```bash
   aws cloudwatch get-metric-statistics \
     --namespace AWS/ElasticBeanstalk \
     --metric-name CPUUtilization \
     --start-time $(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%S) \
     --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
     --period 300 \
     --statistics Average,Maximum \
     --region eu-west-3
   ```

2. Identifier le processus consommateur:
   ```bash
   # Se connecter √† l'instance EB
   eb ssh subscriptions-contracts-eb-prod

   # Top processus CPU
   top -b -n 1 | head -20
   ```

3. V√©rifier les logs pour une charge anormale:
   ```
   CloudWatch Logs Insights:
   fields @timestamp, method, url, duration
   | filter duration > 1000
   | stats count() by url
   | sort count desc
   ```

**Actions**:

1. **Imm√©diat** (si critique):
   - Red√©marrer l'application: `eb restart`
   - V√©rifier que le CPU redescend

2. **Court terme**:
   - Identifier la cause (endpoint lent, boucle infinie, etc.)
   - Appliquer un hotfix si n√©cessaire

3. **Moyen terme**:
   - Optimiser le code identifi√©
   - Augmenter la capacit√© (scale up/out)

**Pr√©vention**:
- Profiling r√©gulier du code
- Load testing avant d√©ploiement
- Auto-scaling configur√©

---

### üü° WARNING: High CPU Utilization (>80%)

**Description**: L'utilisation CPU d√©passe 80%

**Impact**:
- Performances d√©grad√©es
- Risque d'atteindre le seuil critique

**Diagnostic**:
M√™me proc√©dure que CPU >95% mais moins urgent

**Actions**:
1. Surveiller l'√©volution
2. Planifier une investigation
3. V√©rifier les patterns de charge

**Pr√©vention**:
- Monitoring proactif des tendances
- Optimisations pr√©ventives

---

### üî¥ CRITICAL: High Memory Utilization (>90%)

**Description**: L'utilisation m√©moire d√©passe 90%

**Impact**:
- Risque de crash Node.js (Out of Memory)
- Swapping excessif
- Performances tr√®s d√©grad√©es

**Diagnostic**:

1. V√©rifier la m√©moire utilis√©e:
   ```bash
   eb ssh subscriptions-contracts-eb-prod
   free -m
   ps aux | grep node | awk '{print $6}'
   ```

2. Identifier les fuites m√©moire:
   ```bash
   # Heap snapshot (si node-heapdump install√©)
   kill -USR2 $(pgrep node)
   ```

3. V√©rifier les logs pour des patterns:
   ```
   fields @timestamp, @message
   | filter @message like /memory/
   | sort @timestamp desc
   ```

**Actions**:

1. **Imm√©diat**:
   - Red√©marrer l'application: `eb restart`
   - Lib√©rer la m√©moire

2. **Court terme**:
   - Analyser le heap dump
   - Identifier les fuites m√©moire
   - Limiter les objets en cache

3. **Moyen terme**:
   - Corriger les fuites identifi√©es
   - Augmenter la m√©moire disponible
   - Impl√©menter un garbage collection manuel si n√©cessaire

**Pr√©vention**:
- Monitoring heap size
- Limites sur les caches
- Tests de charge m√©moire
- Code review pour d√©tecter les fuites

---

### üü° WARNING: High Disk Space (>85%)

**Description**: L'espace disque d√©passe 85%

**Impact**:
- Risque de saturation du disque
- Impossibilit√© d'√©crire des logs
- Crash de l'application

**Diagnostic**:

1. V√©rifier l'espace disque:
   ```bash
   eb ssh subscriptions-contracts-eb-prod
   df -h
   ```

2. Identifier les gros fichiers:
   ```bash
   du -sh /var/log/* | sort -rh | head -10
   du -sh /var/app/current/* | sort -rh | head -10
   ```

**Actions**:

1. **Imm√©diat**:
   - Nettoyer les vieux logs:
     ```bash
     sudo find /var/log -name "*.log.*" -mtime +7 -delete
     ```
   - Vider les logs de rotation:
     ```bash
     sudo truncate -s 0 /var/log/nodejs/nodejs.log
     ```

2. **Court terme**:
   - Configurer logrotate correctement
   - V√©rifier que CloudWatch Logs fonctionne
   - Augmenter la taille du volume si n√©cessaire

**Pr√©vention**:
- Logrotate configur√© (7 jours de r√©tention)
- Monitoring quotidien de l'espace disque
- CloudWatch Logs pour logs centralis√©s

---

## Alertes Application

### üî¥ CRITICAL: High Error Rate (>5%)

**Description**: Le taux d'erreur API d√©passe 5%

**Impact**:
- Exp√©rience utilisateur d√©grad√©e
- Perte potentielle de revenus
- R√©putation de l'API

**Diagnostic**:

1. Identifier les endpoints en erreur:
   ```
   CloudWatch Logs Insights:
   fields @timestamp, method, url, statusCode
   | filter statusCode >= 400
   | stats count() as error_count by url, statusCode
   | sort error_count desc
   ```

2. Analyser les messages d'erreur:
   ```
   fields @timestamp, level, @message, requestId
   | filter level = "ERROR"
   | sort @timestamp desc
   | limit 100
   ```

3. V√©rifier les d√©pendances:
   - MongoDB: `/health/detailed`
   - Services externes (Stripe, Mailgun)

**Actions**:

1. **Imm√©diat**:
   - Identifier la cause racine
   - Si MongoDB down: v√©rifier la connexion
   - Si service externe down: activer le mode d√©grad√©

2. **Court terme**:
   - D√©ployer un hotfix si bug identifi√©
   - Activer le circuit breaker si service externe d√©faillant
   - Informer les utilisateurs si n√©cessaire

3. **Moyen terme**:
   - Impl√©menter des retry mechanisms
   - Am√©liorer la gestion d'erreurs
   - Tests d'int√©gration renforc√©s

**Pr√©vention**:
- Tests automatis√©s complets
- Circuit breakers sur services externes
- Monitoring proactif des d√©pendances
- Graceful degradation

---

### üî¥ CRITICAL: High 5xx Errors (>10/min)

**Description**: Plus de 10 erreurs serveur par minute

**Impact**:
- Probl√®me serveur s√©rieux
- Service potentiellement indisponible
- Perte de donn√©es possible

**Diagnostic**:

1. Analyser les 5xx r√©centes:
   ```
   fields @timestamp, method, url, statusCode, @message, requestId
   | filter statusCode >= 500
   | sort @timestamp desc
   | limit 50
   ```

2. V√©rifier les exceptions:
   ```
   fields @timestamp, @message, stack
   | filter level = "ERROR"
   | sort @timestamp desc
   ```

3. V√©rifier l'√©tat du syst√®me:
   ```bash
   curl https://api.rt-symphonia.com/health/detailed
   ```

**Actions**:

1. **Imm√©diat**:
   - V√©rifier MongoDB: `mongosh` ou `/health`
   - V√©rifier les logs d'exceptions
   - Rollback si n√©cessaire: `eb deploy --version <previous>`

2. **Court terme**:
   - Corriger le bug identifi√©
   - D√©ployer un hotfix
   - Communiquer avec les utilisateurs

3. **Post-mortem**:
   - Documenter l'incident
   - Ajouter des tests pour √©viter la r√©gression
   - Am√©liorer les health checks

**Pr√©vention**:
- Staging environment avec donn√©es r√©elles
- Canary deployments
- Feature flags pour rollback rapide
- Tests end-to-end automatis√©s

---

### üü° WARNING: High Latency (>1000ms p95)

**Description**: 95% des requ√™tes d√©passent 1 seconde

**Impact**:
- Exp√©rience utilisateur d√©grad√©e
- Timeouts clients possibles
- SLA non respect√©

**Diagnostic**:

1. Identifier les endpoints lents:
   ```
   fields @timestamp, method, url, duration
   | filter duration > 1000
   | stats avg(duration) as avg_duration, max(duration) as max_duration, count() as slow_count by url
   | sort slow_count desc
   ```

2. V√©rifier MongoDB:
   ```
   fields @timestamp, operation, duration
   | filter operation like /MongoDB/
   | stats avg(duration) as avg_db_duration
   ```

3. V√©rifier les appels externes:
   ```
   fields @timestamp, service, duration
   | filter service in ["stripe", "mailgun", "aws"]
   ```

**Actions**:

1. **Court terme**:
   - Identifier les requ√™tes N+1
   - Ajouter des index MongoDB si n√©cessaire
   - Optimiser les requ√™tes lentes

2. **Moyen terme**:
   - Impl√©menter du caching (Redis)
   - Pagination sur les listes
   - Lazy loading

3. **Long terme**:
   - Architecture microservices si n√©cessaire
   - CDN pour assets statiques
   - Database sharding si volume important

**Pr√©vention**:
- Query profiling r√©gulier
- Load testing avec production-like data
- APM (Application Performance Monitoring)
- SLA monitoring

---

### üî¥ CRITICAL: MongoDB Connection Failures (>5/min)

**Description**: Plus de 5 √©checs de connexion MongoDB par minute

**Impact**:
- Service indisponible
- Impossibilit√© de lire/√©crire des donn√©es
- Erreurs 503 aux clients

**Diagnostic**:

1. V√©rifier la connexion MongoDB:
   ```bash
   curl https://api.rt-symphonia.com/health/detailed | jq '.checks.mongodb'
   ```

2. V√©rifier les logs MongoDB:
   ```
   fields @timestamp, @message
   | filter @message like /MongoDB/
   | sort @timestamp desc
   ```

3. V√©rifier MongoDB Atlas (si utilis√©):
   - Dashboard Atlas
   - Connexions actives
   - CPU/Memory du cluster

**Actions**:

1. **Imm√©diat**:
   - V√©rifier les credentials MongoDB
   - V√©rifier le network (Security Groups, IP Whitelist)
   - Red√©marrer la connexion: `eb restart`

2. **Court terme**:
   - V√©rifier la capacit√© du cluster MongoDB
   - Augmenter le pool de connexions si n√©cessaire
   - V√©rifier les index manquants (slow queries)

3. **Moyen terme**:
   - Upgrade du cluster MongoDB si sous-dimensionn√©
   - Impl√©menter un connection retry avec backoff
   - Monitoring proactif MongoDB

**Pr√©vention**:
- Connection pooling configur√©
- Retry logic avec exponential backoff
- Monitoring MongoDB Atlas
- Backup et disaster recovery plan

---

## Alertes Business

### üü° WARNING: Low Order Volume (<5/hour)

**Description**: Moins de 5 commandes par heure

**Impact**:
- Revenus en baisse
- Possible probl√®me technique ou commercial
- Besoin d'investigation

**Diagnostic**:

1. V√©rifier les commandes r√©centes:
   ```
   CloudWatch Logs Insights (business-metrics):
   fields @timestamp, metric, value, metadata.orderId
   | filter metric = "transport_order_created"
   | stats count() by bin(1h)
   ```

2. V√©rifier les erreurs de paiement:
   ```
   fields @timestamp, @message
   | filter @message like /stripe/ or @message like /payment/
   | filter level = "ERROR"
   ```

3. V√©rifier les parcours utilisateurs:
   - Taux de conversion
   - Abandons de panier
   - Erreurs sur formulaire

**Actions**:

1. **Analyse**:
   - Comparer avec les semaines pr√©c√©dentes
   - V√©rifier si jour f√©ri√© / week-end
   - V√©rifier la saisonnalit√©

2. **Investigation**:
   - Tester le parcours de commande
   - V√©rifier les emails de confirmation
   - V√©rifier les int√©grations Stripe

3. **Communication**:
   - Informer l'√©quipe commerciale
   - V√©rifier les campagnes marketing
   - Analyser le trafic web

**Pr√©vention**:
- Monitoring des KPIs business
- A/B testing
- Analytics d√©taill√©es
- Alertes sur baisse de trafic

---

### üü° WARNING: High Delivery Delay Rate (>20%)

**Description**: Plus de 20% des livraisons sont en retard

**Impact**:
- Satisfaction client d√©grad√©e
- Risque de p√©nalit√©s contractuelles
- R√©putation de la plateforme

**Diagnostic**:

1. Identifier les livraisons en retard:
   ```
   fields @timestamp, metadata.orderId, metadata.delay, metadata.carrierId
   | filter metric = "delivery_completed" and metadata.onTime = false
   | sort metadata.delay desc
   | limit 50
   ```

2. Analyser par transporteur:
   ```
   fields metadata.carrierId
   | filter metric = "delivery_completed"
   | stats sum(metadata.onTime = false) as delayed, count() as total by metadata.carrierId
   | eval delay_rate = delayed / total * 100
   | sort delay_rate desc
   ```

3. V√©rifier les causes:
   - Probl√®mes de trafic
   - M√©t√©o
   - Probl√®me sp√©cifique transporteur
   - Estimation ETA incorrecte

**Actions**:

1. **Court terme**:
   - Identifier les transporteurs probl√©matiques
   - Contacter les transporteurs en retard
   - Informer les clients affect√©s

2. **Moyen terme**:
   - Ajuster les scores des transporteurs
   - Revoir les estimations ETA
   - Impl√©menter des alertes proactives

3. **Long terme**:
   - Machine Learning pour pr√©diction ETA
   - Diversification des transporteurs
   - P√©nalit√©s contractuelles pour retards

**Pr√©vention**:
- Monitoring temps r√©el des livraisons
- Alertes pr√©ventives sur retards potentiels
- Buffer dans les estimations ETA
- Qualit√© des transporteurs r√©f√©renc√©s

---

### üü° WARNING: Low Carrier Score (<70)

**Description**: Score moyen des transporteurs en dessous de 70

**Impact**:
- Qualit√© de service d√©grad√©e
- Risque de probl√®mes op√©rationnels
- Insatisfaction clients

**Diagnostic**:

1. Identifier les transporteurs probl√©matiques:
   ```
   fields @timestamp, metadata.carrierId, metadata.newScore
   | filter metric = "carrier_score_updated"
   | stats avg(metadata.newScore) as avg_score by metadata.carrierId
   | filter avg_score < 70
   | sort avg_score asc
   ```

2. Analyser les facteurs de score:
   - Ponctualit√©
   - Qualit√© du service
   - Satisfaction client
   - Incidents

**Actions**:

1. **Imm√©diat**:
   - Contacter les transporteurs concern√©s
   - V√©rifier les r√©clamations clients
   - Analyser les incidents r√©cents

2. **Court terme**:
   - Plan d'am√©lioration avec le transporteur
   - Suspension temporaire si n√©cessaire
   - Recherche de transporteurs alternatifs

3. **Long terme**:
   - Crit√®res de s√©lection plus stricts
   - Programme de formation transporteurs
   - Syst√®me de bonus/malus

**Pr√©vention**:
- √âvaluation r√©guli√®re des transporteurs
- Feedback clients syst√©matique
- Audits qualit√© p√©riodiques
- Seuils de performance contractuels

---

## Proc√©dures d'escalade

### Niveau 1: Astreinte DevOps

**D√©clencheurs**:
- Alertes WARNING
- Alertes hors heures ouvr√©es
- Incidents mineurs

**Actions**:
- Investigation initiale (30 min max)
- Application de solutions standards
- Escalade si non r√©solu

**D√©lai de r√©ponse**: 30 minutes

---

### Niveau 2: Lead Technique

**D√©clencheurs**:
- Alertes CRITICAL
- Non r√©solution niveau 1
- Impact utilisateurs important

**Actions**:
- Investigation approfondie
- Coordination √©quipe technique
- Communication parties prenantes
- Escalade si n√©cessaire

**D√©lai de r√©ponse**: 15 minutes

---

### Niveau 3: CTO / Management

**D√©clencheurs**:
- Incident majeur (>1h)
- Impact business significatif
- Donn√©es sensibles compromises
- Communication externe n√©cessaire

**Actions**:
- D√©cisions strat√©giques
- Communication clients/presse
- Activation plan de continuit√©
- Post-mortem

**D√©lai de r√©ponse**: 5 minutes

---

## Contacts d'urgence

### √âquipe Technique

| R√¥le | Nom | Email | T√©l√©phone | Disponibilit√© |
|------|-----|-------|-----------|---------------|
| DevOps L1 | Astreinte DevOps | devops-oncall@rt-symphonia.com | +33 6 XX XX XX XX | 24/7 |
| Lead Tech | [Nom] | lead-tech@rt-symphonia.com | +33 6 XX XX XX XX | 24/7 |
| CTO | [Nom] | cto@rt-symphonia.com | +33 6 XX XX XX XX | 24/7 |

### Support AWS

- **AWS Support Premium**: https://console.aws.amazon.com/support/
- **T√©l√©phone**: 0800 XXX XXX (France)
- **Disponibilit√©**: 24/7

### Partenaires Externes

| Service | Contact | Support |
|---------|---------|---------|
| MongoDB Atlas | support@mongodb.com | 24/7 |
| Stripe | https://support.stripe.com | 24/7 |
| Mailgun | support@mailgun.com | Email |

---

## Outils de diagnostic

### Commandes essentielles

```bash
# √âtat de l'application
eb status
eb health --refresh

# Logs en temps r√©el
eb logs --stream

# SSH instance
eb ssh

# M√©triques CloudWatch
aws cloudwatch get-metric-statistics ...

# Restart
eb restart
```

### Dashboards

- **CloudWatch**: https://console.aws.amazon.com/cloudwatch/
- **Elastic Beanstalk**: https://console.aws.amazon.com/elasticbeanstalk/
- **MongoDB Atlas**: https://cloud.mongodb.com/

---

**Version**: 1.0.0
**Derni√®re mise √† jour**: 26 novembre 2025
**Auteur**: RT SYMPHONI.A DevOps Team
